# core/memory/memory.py ‚Äî –ü–∞–º—è—Ç—å v0.0.3
import os
from typing import List, Optional
from core.common.utils import load_json, save_json, generate_id, timestamp
from core.common.types import Fact, KnowledgeEntry, KnowledgeType
from core.learner.rules import rules_engine
from core.processor.classifier import Classifier
from core.processor.tokenizer import Tokenizer
from core.common.log import get_logger
from config import MEMORY, LOGGING

logger = get_logger(__name__)

class Memory:
    """
    –ö–ª–∞—Å—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é –ò–ò:
    - –•—Ä–∞–Ω–∏—Ç —Ñ–∞–∫—Ç—ã –∏ –∑–Ω–∞–Ω–∏—è
    - –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–∫–∞—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    - –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ –∑–Ω–∞–Ω–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
    """

    def __init__(self, memory_path: Optional[str] = None, knowledge_path: Optional[str] = None):
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        self.memory_path = memory_path or MEMORY.get("memory_file", "data/memory.json")
        self.knowledge_path = knowledge_path or MEMORY.get("knowledge_file", "data/knowledge.json")

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        self.max_facts = MEMORY.get("max_facts", 5000)

        # –ú–æ–¥—É–ª–∏
        self.classifier = Classifier()
        self.tokenizer = Tokenizer()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞–º—è—Ç—å
        self.facts = self._load_facts()
        self.knowledge = self._load_knowledge()

        logger.info(
            f"{LOGGING['prefix_memory']} –ü–∞–º—è—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. "
            f"–§–∞–∫—Ç–æ–≤: {len(self.facts)}, –ó–Ω–∞–Ω–∏–π: {len(self.knowledge)}"
        )

    # === üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    def _load_facts(self) -> List[Fact]:
        if not os.path.exists(self.memory_path):
            logger.warning(f"{LOGGING['prefix_memory']} –§–∞–π–ª –ø–∞–º—è—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.memory_path}")
            return []
        try:
            data = load_json(self.memory_path)
            facts = [Fact(**f) for f in data.get("facts", [])]
            logger.debug(f"{LOGGING['prefix_memory']} –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {len(facts)}")
            return facts
        except Exception as e:
            logger.exception(f"{LOGGING['prefix_memory']} –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–∫—Ç–æ–≤: {e}")
            return []

    def _load_knowledge(self) -> List[KnowledgeEntry]:
        if not os.path.exists(self.knowledge_path):
            logger.warning(f"{LOGGING['prefix_memory']} –§–∞–π–ª –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.knowledge_path}")
            return []
        try:
            data = load_json(self.knowledge_path)
            knowledge = [KnowledgeEntry(**k) for k in data.get("entries", [])]
            logger.debug(f"{LOGGING['prefix_memory']} –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–Ω–∞–Ω–∏–π: {len(knowledge)}")
            return knowledge
        except Exception as e:
            logger.exception(f"{LOGGING['prefix_memory']} –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∑–Ω–∞–Ω–∏–π: {e}")
            return []

    # === üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ===
    def _save_facts(self):
        try:
            data = {"facts": [f.__dict__ for f in self.facts]}
            save_json(self.memory_path, data)
            logger.info(f"{LOGGING['prefix_memory']} –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤: {len(self.facts)}")
        except Exception as e:
            logger.exception(f"{LOGGING['prefix_memory']} –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤: {e}")

    def _save_knowledge(self):
        try:
            data = {
                "entries": [
                    {
                        **k.__dict__,
                        "type": k.type.value if hasattr(k.type, "value") else k.type
                    }
                    for k in self.knowledge
                ]
            }
            save_json(self.knowledge_path, data)
            logger.info(f"{LOGGING['prefix_memory']} –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∑–Ω–∞–Ω–∏–π: {len(self.knowledge)}")
        except Exception as e:
            logger.exception(f"{LOGGING['prefix_memory']} –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–Ω–∞–Ω–∏–π: {e}")

    # === ‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö ===
    def add_fact(self, subject: str, predicate: str, obj: str, source: Optional[str] = None) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —Ñ–∞–∫—Ç –≤ –ø–∞–º—è—Ç—å —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∏ –ª–∏–º–∏—Ç"""
        if len(self.facts) >= self.max_facts:
            logger.error(f"{LOGGING['prefix_memory']} –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç —Ñ–∞–∫—Ç–æ–≤ ({self.max_facts}).")
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç
        for f in self.facts:
            if f.subject == subject and f.predicate == predicate and f.obj == obj:
                logger.warning(f"{LOGGING['prefix_memory']} –§–∞–∫—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {subject} ‚Äî {predicate} ‚Äî {obj}")
                return False

        fact = Fact(
            id=generate_id(),
            subject=subject,
            predicate=predicate,
            obj=obj,
            source=source,
            timestamp=timestamp()
        )
        self.facts.append(fact)
        self._save_facts()
        logger.info(f"{LOGGING['prefix_memory']} –ù–æ–≤—ã–π —Ñ–∞–∫—Ç: {subject} ‚Äî {predicate} ‚Äî {obj}")
        return True

    def add_knowledge(self, title: str, content: str, k_type: KnowledgeType, tags: List[str]):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∑–Ω–∞–Ω–∏–π"""
        entry = KnowledgeEntry(
            id=generate_id(),
            title=title,
            content=content,
            type=k_type,
            tags=tags,
            created=timestamp()
        )
        self.knowledge.append(entry)
        self._save_knowledge()
        logger.info(f"{LOGGING['prefix_memory']} –ù–æ–≤–æ–µ –∑–Ω–∞–Ω–∏–µ: {title}")

    # === üîç –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö ===
    def search_fact_by_token(self, token: str) -> List[str]:
        token = token.lower().strip()
        return [
            f"{f.subject} ‚Äî {f.predicate} ‚Äî {f.obj}"
            for f in self.facts
            if token in f.subject.lower() or token in f.obj.lower()
        ]

    def find_facts_by_subject(self, subject: str) -> List[Fact]:
        return [f for f in self.facts if subject.lower() == f.subject.lower()]

    def find_knowledge_by_tag(self, tag: str) -> List[KnowledgeEntry]:
        return [k for k in self.knowledge if tag in k.tags]

    # === üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∞–∫—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ ===
    def add_fact_from_text(self, text: str) -> bool:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ"""
        try:
            phrase_type = self.classifier.classify(text)
            tokens = self.tokenizer.tokenize(text)
            result = rules_engine.apply_rules(phrase_type, tokens, text)

            if result and result.get("type") == "fact":
                return self.add_fact(
                    subject=result["subject"],
                    predicate=result["predicate"],
                    obj=result["object"],
                    source=result.get("source")
                )

            logger.debug(f"{LOGGING['prefix_memory']} –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç: '{text}'")
            return False
        except Exception as e:
            logger.exception(f"{LOGGING['prefix_memory']} –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return False
